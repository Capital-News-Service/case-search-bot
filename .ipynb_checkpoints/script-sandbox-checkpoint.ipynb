{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code scrapes the maryland case search database and send slack messages when new interesting cases are found. \n",
    "# To be ran on a schedule.\n",
    "\n",
    "# To run you will need to update the config file with your slack webhook endpoints\n",
    "# This is in an array if you would like to have multiple enpoints, but if it just one that is ok too, just leave it as an array with one element\n",
    "# (you need to set up te slack bot and get endpoint, it is relativly simple follow instuctions here)\n",
    "# https://api.slack.com/incoming-webhooks\n",
    "# Set up search add in configs for search that takes place here \n",
    "# http://casesearch.courts.state.md.us/casesearch/processDisclaimer.jis\n",
    "\n",
    "# Ours looks like this:\n",
    "# \"partyType\" : \"DEF\",\n",
    "# \"county\" : \"ANNE ARUNDEL COUNTY\",\n",
    "# \"site\" : \"CRIMINAL\",\n",
    "# \"company\" : \"N\",\n",
    "# \"courtSystem\" : \"B\"}\n",
    "\n",
    "# Add your cjis codes for crimes that are intersting to you\n",
    "# https://mdcourts.gov/sites/default/files/import/district/charginglanguage_102018.pdf?pdf=Charging-Language\n",
    "\n",
    "# Here is how it works at a high level:\n",
    "\n",
    "# On run\n",
    "#Step 1) Load in config data from key file. Happens at top of page\n",
    "#Step 2) Get a authenitcated cookie to use for our searches. In getCookie():\n",
    "#Step 3) Do a search for results from last day that fit your search. In getPage(cookie, page):\n",
    "#Step 4) Collect these searches if they are the right case type. In getPage(cookie, page):\n",
    "#Step 5) Load in last search results. In compare_cases(new_cases, cookie):\n",
    "#Step 6) Compare new and old search results, if they are different continue. In compare_cases(new_cases, cookie):\n",
    "#Step 7) For new unique cases load individual case pages. In getSingleCase(cookie, caseId):\n",
    "#Step 8) Read page and gather information and charges list. We read the page here so we can minimize the number of page loads. In getSingleCase(cookie, caseId):\n",
    "#Step 9) If any charges are in our list of cjis codes build and send message to slack. In send_alert(row, cookie):\n",
    "#Step 10) Save new results as old. In compare_cases(new_cases, cookie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MURDER-FIRST DEGREE : 1-0990\n",
    "# MURDER-SECOND DEGREE : 1-1107 \n",
    "# ATT 1ST DEG. MURDER : 2-0910\n",
    "# ATT 2ND DEG. MURDER : 2-0920\n",
    "# MANSLAUGHTER : 1-0910\n",
    "# INVOLUNTARY MANSLAUGHTER : 1-0911\n",
    "# NEG MANSL-AUTO/BOAT, ETC : 1-0909\n",
    "# CRIM NEG MANSLAUGHTER BY VEH/VESS : 1-1611\n",
    "# NEG AUTO/BOAT HMCD-UNDER INFLU : 1-0900\n",
    "# HOMICIDE-MV/VESSEL-IMPAIR ALC : 1-0693\n",
    "# HOMICIDE-MV/VESSEL-DRUGS : 1-0755\n",
    "# HOMICIDE-MV/VESSEL-CDS : 1-1436\n",
    "# CDS DIST/DISPENSE- LG AMT : 1-0880\n",
    "# CDS MANUF - LG AMT : 1-0879\n",
    "# CDS-DRUG KINGPIN : 1-0488\n",
    "# ASSAULT-FIRST DEGREE : 1-1420\n",
    "# ASSAULT-SEC DEGREE : 1-1415\n",
    "# FIREARM USE/FEL-VIOL CRIME : 1-1415 \n",
    "# FIREARM USE/FEL-VIOL CRIME : 1-5212 \n",
    "\n",
    "# Use a - not an underscore in the code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load needed libraries\n",
    "import boto\n",
    "import boto.s3.connection\n",
    "import boto3\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1\n",
      "Scraping Page 2\n",
      "Scraping Page 3\n",
      "Done Scraping\n",
      "Total Found Cases: 18\n",
      "-10 New Cases\n",
      "D111CR19004910\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-18b027895d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mcompare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m \u001b[0mrunBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-18b027895d21>\u001b[0m in \u001b[0;36mrunBot\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mcookie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCookie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mcompare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0mrunBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-18b027895d21>\u001b[0m in \u001b[0;36mcompare_cases\u001b[0;34m(new_cases, cookie)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_cases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caseId\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caseId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0msend_alert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m#if this is the first ever run, just send all cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-18b027895d21>\u001b[0m in \u001b[0;36msend_alert\u001b[0;34m(row, cookie)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend_alert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mcharges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mcharge_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCharges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caseId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m#build message text if qualified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-18b027895d21>\u001b[0m in \u001b[0;36mgetCharges\u001b[0;34m(cookie, caseId)\u001b[0m\n\u001b[1;32m    122\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             \u001b[0mnew_spans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                             \u001b[0mcharge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_spans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcharge\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    740\u001b[0m             raise AttributeError(\n\u001b[1;32m    741\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[0;32m--> 742\u001b[0;31m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "#load in sensitive and configuration information from seperate key file\n",
    "keys={}\n",
    "with open(\"config.json\",\"r\") as f:\n",
    "    config = json.loads(f.read())\n",
    "   \n",
    "    \n",
    "slack_urls = config[\"urls\"]\n",
    "codes = config[\"codes\"]\n",
    "partyType = config['partyType']\n",
    "county = config[\"county\"]\n",
    "site = config['site']\n",
    "company = config['company']\n",
    "courtSystem = config[\"courtSystem\"]\n",
    "\n",
    "#load in AWS bucket keys info\n",
    "db_access_key = config[\"db_access_key\"]\n",
    "db_secret_key = config[\"db_secret_key\"]\n",
    "bucket_name = config[\"db_bucket_name\"] \n",
    "object_key = config[\"db_object_key\"] \n",
    "\n",
    "# Creation of the actual interface, using authentication\n",
    "s3 = boto3.resource('s3',\n",
    "         aws_access_key_id=db_access_key,\n",
    "         aws_secret_access_key=db_secret_key)\n",
    "my_bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "#Get an authenticated cookie for searches\n",
    "#before doing a request you will need to get a cookie to show yo have agreed to the disclamer, \n",
    "#we will send a post request showing we have done this and return the cookie aquired for our later searches\n",
    "def getCookie():\n",
    "    session = requests.Session()\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/'\n",
    "    params = {\n",
    "            'disclaimer' : 'Y',\n",
    "            'action' : 'Continue'\n",
    "    }\n",
    "    r = session.post(url, data=params)\n",
    "\n",
    "    cook = session.cookies['JSESSIONID']\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    return \"JSESSIONID=\" + cook\n",
    "    \n",
    "#search case search for single cases results by case number and return page\n",
    "def getSingleCase(cookie, caseId):\n",
    "\n",
    "    headers = {'Cookie': cookie}\n",
    "\n",
    "    params = {\n",
    "        'caseId' : caseId,\n",
    "        'action': 'Get Case',\n",
    "        'locationCode': 'B'\n",
    "    }\n",
    "\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/inquiryByCaseNum.jis'\n",
    "    r = requests.post(url, params=params, headers=headers)\n",
    "    return r.text\n",
    "\n",
    "#search casesearch for possible cases and return page\n",
    "def getPage(cookie, page):\n",
    "    headers = {'Cookie': cookie}\n",
    "\n",
    "    today = datetime.datetime.today().strftime('%m/%d/%Y')\n",
    "    yesterday = (datetime.datetime.today() - timedelta(1)).strftime('%m/%d/%Y')\n",
    "    params = {\n",
    "        'd-16544-p': page,\n",
    "        'lastName': '%', \n",
    "        'firstName' : '',\n",
    "        'middleName': '',  \n",
    "        'partyType': partyType,\n",
    "        'site': site,\n",
    "        'courtSystem': courtSystem,\n",
    "        'countyName': county,\n",
    "        'filingStart': yesterday,\n",
    "        'filingEnd': today,\n",
    "        'filingDate': '',\n",
    "        'company': company,\n",
    "        'action': 'Search',\n",
    "    }\n",
    "\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/inquirySearch.jis'\n",
    "    r = requests.post(url, params=params, headers=headers)\n",
    "    time.sleep(1)\n",
    "    return r.text\n",
    "\n",
    "#Get charges for one individual cases\n",
    "def getCharges(cookie, caseId):\n",
    "    print(caseId)\n",
    "    #data we will gather from individual case page\n",
    "    charges = []\n",
    "    cjiss = []\n",
    "    text = getSingleCase(cookie, caseId)\n",
    "    soup = BeautifulSoup(text)\n",
    "    windows = soup.find_all(\"div\", attrs={'class':'AltBodyWindow1'})\n",
    "    #search through each window in the page. for now we just go through each td on the page and it works\n",
    "    #this could be more efficient if we first chack to make sure the window contains the text before searching\n",
    "    for window in windows:\n",
    "        #find each table in current window\n",
    "        tables = window.find_all(\"table\")\n",
    "        for table in tables:\n",
    "            #find every tr in this table\n",
    "            for row in table.findAll('tr'):\n",
    "                #for each tr search for each td and if it is a charge information window read it. \n",
    "                # No other point on the page will contain this text\n",
    "                for span in row.findAll('span'):\n",
    "                    #get cjis number for each charge\n",
    "                    if (span.text == 'CJIS Code:' or span.text == 'CJIS/Traffic Code:'):\n",
    "                        target = span.next_sibling\n",
    "                        if (target == None):\n",
    "                            new_row = row.next_sibling\n",
    "#                             new_spans = new_row.findAll(\"span\")\n",
    "#                             cjis = new_spans[0].text              \n",
    "#                             cjiss.append(cjis.replace(\" \", \"-\"))\n",
    "                        else:\n",
    "                            cjis = target.text              \n",
    "                            cjiss.append(cjis.replace(\" \", \"-\"))\n",
    "\n",
    "                    #get charge description for each charge\n",
    "                    if (span.text == 'Charge Description:' or span.text == 'Description:'):\n",
    "                        target = span.next_sibling\n",
    "                        if (target == None):\n",
    "                            new_row = row.next_sibling\n",
    "#                             new_spans = new_row.findAll(\"span\")\n",
    "#                             charge = new_spans[0].text \n",
    "#                             if (charge != \"\"):\n",
    "#                                 charges.append(charge)\n",
    "                        else:\n",
    "                            charge = target.text\n",
    "                            if (charge != \"\"):\n",
    "                                charges.append(charge)\n",
    "     \n",
    "    # build dataset from gathered information and return it\n",
    "    charge_data = {\"charge\": charges, \"cjis\" : cjiss}\n",
    "    return charge_data\n",
    "    \n",
    "#Run search and return information on all current cases  \n",
    "def getCases(cookie):\n",
    "    \n",
    "    end_reached = False\n",
    "    page = 1\n",
    "    \n",
    "    #data we will collect\n",
    "    caseIds = []\n",
    "    links = []\n",
    "    names = []\n",
    "    types = []\n",
    "    dates = []\n",
    "    \n",
    "    #keep scraping until you have reached the last page of results\n",
    "    while (end_reached == False):\n",
    "        \n",
    "        text = getPage(cookie, page)\n",
    "        soup = BeautifulSoup(text)\n",
    "        \n",
    "        #test if last page reached\n",
    "        banner = soup.find(\"span\", attrs={'class':'pagebanner'}).text\n",
    "        splits = banner.split(\" \", 6)\n",
    "        if (splits[0] == splits[6][:-1]):\n",
    "            #if last page has been reach set to false so we do not continue\n",
    "            end_reached = True\n",
    "        table = soup.find(\"table\", attrs={'id':'row'})\n",
    "        body = table.find(\"tbody\")\n",
    "        rows = body.find_all(\"tr\")\n",
    "        cases_on_page = len(rows)\n",
    "\n",
    "        #for every charge listed in the results page, pull out data and make a dataframe\n",
    "        for row in rows:\n",
    "            tds = row.find_all(\"td\")\n",
    "            caseType = tds[5].text\n",
    "            if (caseType == \"CRSCA\" or caseType == \"CROVA\" or caseType == \"CR\" or caseType == \"CRIMINAL\"):\n",
    "                if (tds[0].find(\"a\") != None):\n",
    "                    #collect data for individual case here \n",
    "                    links.append(\"http://casesearch.courts.state.md.us/casesearch/\" + tds[0].find(\"a\")['href'])\n",
    "                    caseId = tds[0].find(\"a\").text\n",
    "                    caseIds.append(caseId)\n",
    "                    names.append(tds[1].text)\n",
    "                    types.append(caseType)\n",
    "                    dates.append(tds[7].text)\n",
    "                    \n",
    "        print(\"Scraping Page \" + str(page))\n",
    "        page = page+1\n",
    "\n",
    "\n",
    "    #create dataframe from gathered info\n",
    "    cases = pd.DataFrame(\n",
    "        {'caseId': caseIds,\n",
    "         'name': names,\n",
    "         \"type\": types,\n",
    "         \"date\": dates,\n",
    "         \"link\" : links\n",
    "        })\n",
    "\n",
    "    print(\"Done Scraping\")\n",
    "    return cases\n",
    "\n",
    "#Post message on slack if it is qualified. We check if the charges for each case are interesting here because it is time consuming\n",
    "def send_alert(row, cookie):\n",
    "    charges = \"\"\n",
    "    charge_data = getCharges(cookie, row[\"caseId\"])\n",
    "    \n",
    "    #build message text if qualified\n",
    "    \n",
    "    #check if any of the charges are part of our list of interesting charges, \n",
    "    #from json file codes, a list of cjis codes of interesting crimes\n",
    "    qualified = False\n",
    "    for charge in charge_data[\"cjis\"]:\n",
    "        if charge in codes:\n",
    "            qualified = True\n",
    "    \n",
    "    #if one of the cases cjis codes is in our list send the alert\n",
    "    if qualified:\n",
    "        \n",
    "        #build the message text by looking through and adding charges to a string\n",
    "        charge_num = 1\n",
    "        for c,j in zip(charge_data['charge'],charge_data['cjis']):\n",
    "            if charges == \"\":\n",
    "                charges = \"\\n1) \" + c + \" : \" + j\n",
    "            else:\n",
    "                charges = charges + \" \\n\" + str(charge_num) + \") \" + c + \" : \" + j\n",
    "            charge_num = charge_num + 1\n",
    "\n",
    "        #combine interesting info and charge list insto one string\n",
    "        message = row['name'] + \" - \" + row['date'] + charges + \" \\n\" + row['link'] +\" \\n-------------------------\"\n",
    "        print(message)\n",
    "        #build post request to send to slack bot\n",
    "        slack_data = {'text': message}\n",
    "        headers={'Content-Type': 'application/json'}\n",
    "        \n",
    "        #sedn post to every slack we have set up, it will still work if it is just one\n",
    "        for slack_url in slack_urls:\n",
    "            url = slack_url\n",
    "            print(\"send alert\")\n",
    "            #send post request with message text\n",
    "#             r = requests.post(url, json=slack_data, headers=headers)\n",
    "\n",
    "def readDatabase():\n",
    "\n",
    "    with open('/tmp/cases.json','wb') as data:\n",
    "        my_bucket.download_fileobj(object_key, data)\n",
    "\n",
    "    old_cases={}\n",
    "    with open(\"/tmp/cases.json\",\"r\") as f:\n",
    "         text = f.read()\n",
    "    \n",
    "    old_cases = pd.read_json(text)\n",
    "    \n",
    "    return old_cases\n",
    "\n",
    "def updateDatabase(json_data):\n",
    "\n",
    "    with open('/tmp/cases.json', 'wb') as outfile:\n",
    "        outfile.write(json_data)\n",
    "\n",
    "    with open('/tmp/cases.json', 'rb') as data:\n",
    "        my_bucket.upload_fileobj(data, object_key)\n",
    "\n",
    "#Find new cases and post them on slack\n",
    "def compare_cases(new_cases, cookie):\n",
    "    #load cases from last search\n",
    "    old_cases = readDatabase()\n",
    "#     old_cases = pd.read_json('cases.json')\n",
    "    \n",
    "    print(\"Total Found Cases: \" + str(len(new_cases)))\n",
    "    print(str(len(new_cases)-len(old_cases)) + \" New Cases\")\n",
    "\n",
    "    # basically just check if this is the first time you have run the search, \n",
    "    # make sure to create a empty cases.jsons file that is just {} before starting the bot\n",
    "    if (len(old_cases) != 0):\n",
    "        #see if any results are new and if they are post them on slack\n",
    "        for index, row in new_cases.iterrows():\n",
    "            if row[\"caseId\"] not in old_cases['caseId'].unique():\n",
    "                send_alert(row, cookie)\n",
    "    else:\n",
    "        #if this is the first ever run, just send all cases\n",
    "        for index, row in new_cases.iterrows():\n",
    "            send_alert(row, cookie)\n",
    "\n",
    "    #save new cases to be the old cases when the script runs again\n",
    "    json_data = new_cases.to_json()\n",
    "#     updateDatabase(json_data.encode('utf-8'))\n",
    "#     new_cases.to_json('cases.json')\n",
    "  \n",
    "#Run bot\n",
    "def runBot():\n",
    "    cookie = getCookie()\n",
    "    cases = getCases(cookie)\n",
    "    compare_cases(cases, cookie)\n",
    "\n",
    "runBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
