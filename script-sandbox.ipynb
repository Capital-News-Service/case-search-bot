{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code scrapes the maryland case search database and send slack messages when new interesting cases are found. To be ran on a schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load needed libraries\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 items found, displaying 1 to 25.\n",
      "Scraping Page 1\n",
      "75 items found, displaying 26 to 50.\n",
      "Scraping Page 2\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 3\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 4\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 5\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 6\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 7\n",
      "75 items found, displaying 51 to 75.\n",
      "Scraping Page 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1b220597a288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mcompare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m \u001b[0mrunBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-1b220597a288>\u001b[0m in \u001b[0;36mrunBot\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mcookie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCookie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mcompare_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-1b220597a288>\u001b[0m in \u001b[0;36mgetCases\u001b[0;34m(cookie)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_reached\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mbanner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pagebanner'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-1b220597a288>\u001b[0m in \u001b[0;36mgetPage\u001b[0;34m(cookie, page)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://casesearch.courts.state.md.us/casesearch/inquirySearch.jis'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load in sensitive information from seperate key file\n",
    "keys={}\n",
    "with open(\"keys.json\",\"r\") as f:\n",
    "    keys = json.loads(f.read())\n",
    "   \n",
    "    \n",
    "slack_url = keys[\"url\"]\n",
    "codes = keys[\"codes\"]\n",
    "partyType = keys['partyType']\n",
    "county = keys[\"county\"]\n",
    "site = keys['site']\n",
    "company = keys['company']\n",
    "courtSystem = keys[\"courtSystem\"]\n",
    "\n",
    "#Get an authenticated cookie for searches\n",
    "def getCookie():\n",
    "    session = requests.Session()\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/'\n",
    "    params = {\n",
    "            'disclaimer' : 'Y',\n",
    "            'action' : 'Continue'\n",
    "    }\n",
    "    r = session.post(url, data=params)\n",
    "\n",
    "    cook = session.cookies['JSESSIONID']\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    return \"JSESSIONID=\" + cook\n",
    "    \n",
    "#search case search for single cases results by case number and return page\n",
    "def getSingleCase(cookie, caseId):\n",
    "\n",
    "    headers = {'Cookie': cookie}\n",
    "\n",
    "    params = {\n",
    "        'caseId' : caseId,\n",
    "        'action': 'Get Case',\n",
    "        'locationCode': 'B'\n",
    "    }\n",
    "\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/inquiryByCaseNum.jis'\n",
    "    r = requests.post(url, params=params, headers=headers)\n",
    "    return r.text\n",
    "\n",
    "#search casesearch for possible cases and return page\n",
    "def getPage(cookie, page):\n",
    "    headers = {'Cookie': cookie}\n",
    "\n",
    "    today = datetime.datetime.today().strftime('%m/%d/%Y')\n",
    "    yesterday = (datetime.datetime.today() - timedelta(1)).strftime('%m/%d/%Y')\n",
    "    params = {\n",
    "        'd-16544-p': page,\n",
    "        'lastName': '%', \n",
    "        'firstName' : '',\n",
    "        'middleName': '',  \n",
    "        'partyType': partyType,\n",
    "        'site': site,\n",
    "        'courtSystem': courtSystem,\n",
    "        'countyName': county,\n",
    "        'filingStart': \"1/22/2019\",\n",
    "        'filingEnd': \"1/23/2019\",\n",
    "        'filingDate': '',\n",
    "        'company': company,\n",
    "        'action': 'Search',\n",
    "    }\n",
    "\n",
    "    url = 'http://casesearch.courts.state.md.us/casesearch/inquirySearch.jis'\n",
    "    r = requests.post(url, params=params, headers=headers)\n",
    "    time.sleep(1)\n",
    "    return r.text\n",
    "\n",
    "#Get charges for one individual cases\n",
    "def getCharges(cookie, caseId):\n",
    "    \n",
    "    #data we will gather from individual case page\n",
    "    charges = []\n",
    "    cjiss = []\n",
    "    text = getSingleCase(cookie, caseId)\n",
    "    soup = BeautifulSoup(text)\n",
    "    windows = soup.find_all(\"div\", attrs={'class':'AltBodyWindow1'})\n",
    "    for window in windows:\n",
    "        tables = window.find_all(\"table\")\n",
    "        for table in tables:\n",
    "            for row in table.findAll('tr'):\n",
    "                cell = row.findNext('td')\n",
    "                \n",
    "                #get cjis number for each charge\n",
    "                if cell.text == 'Charge No:':\n",
    "                    target = cell.next_sibling\n",
    "                    spans = target.find_all(\"span\")\n",
    "                    cjis = spans[2].text\n",
    "                    cjiss.append(cjis)\n",
    "\n",
    "                #get charge description for each charge\n",
    "                if cell.text == 'Charge Description:':\n",
    "                    target = cell.next_sibling\n",
    "                    spans = target.find_all(\"span\")\n",
    "                    charge = spans[0].text              \n",
    "                    charges.append(charge)\n",
    "     \n",
    "    charge_data = {\"charge\": charges, \"cjis\" : cjiss}\n",
    "    return charge_data\n",
    "    \n",
    "#Run search and return information on all current cases  \n",
    "def getCases(cookie):\n",
    "    \n",
    "    end_reached = False\n",
    "    page = 1\n",
    "    \n",
    "    #data we will collect\n",
    "    caseIds = []\n",
    "    links = []\n",
    "    names = []\n",
    "    types = []\n",
    "    dates = []\n",
    "    \n",
    "    #keep scraping until you have reached the last page of results\n",
    "    while (end_reached == False):\n",
    "        \n",
    "        text = getPage(cookie, page)\n",
    "        soup = BeautifulSoup(text)\n",
    "        \n",
    "        #test if last page reached\n",
    "        banner = soup.find(\"span\", attrs={'class':'pagebanner'}).text\n",
    "        splits = banner.split(\" \", 6)\n",
    "        if (splits[0] == splits[6][:-1]):\n",
    "            end_reached = True\n",
    "        table = soup.find(\"table\", attrs={'id':'row'})\n",
    "        body = table.find(\"tbody\")\n",
    "        rows = body.find_all(\"tr\")\n",
    "        cases_on_page = len(rows)\n",
    "\n",
    "        for row in rows:\n",
    "            tds = row.find_all(\"td\")\n",
    "            caseType = tds[5].text\n",
    "            if caseType == \"CRSCA\" or caseType == \"CROVA\":\n",
    "                if (tds[0].find(\"a\") != None):\n",
    "                    links.append(\"http://casesearch.courts.state.md.us/casesearch/\" + tds[0].find(\"a\")['href'])\n",
    "                    caseId = tds[0].find(\"a\").text\n",
    "                    caseIds.append(caseId)\n",
    "                    names.append(tds[1].text)\n",
    "                    types.append(caseType)\n",
    "                    dates.append(tds[7].text)\n",
    "\n",
    "        #create dataframe from gathered info\n",
    "        cases = pd.DataFrame(\n",
    "            {'caseId': caseIds,\n",
    "             'name': names,\n",
    "             \"type\": types,\n",
    "             \"date\": dates,\n",
    "             \"link\" : links\n",
    "            })\n",
    "        \n",
    "        print(\"Scraping Page \" + str(page))\n",
    "        page = page+1\n",
    "\n",
    "    print(\"Done Scraping\")\n",
    "    return cases\n",
    "\n",
    "#Post message on slack if it is qualified. We check if the charges for each case are interesting here because it is time consuming\n",
    "def send_alert(row, cookie):\n",
    "    print(\"send alert\")\n",
    "    charges = \"\"\n",
    "    charge_data = getCharges(cookie, row[\"caseId\"])\n",
    "    \n",
    "    #build message text if qualified\n",
    "    \n",
    "    qualified = False\n",
    "    for charge in charges:\n",
    "        if charge in codes:\n",
    "            qualified = True\n",
    "            \n",
    "    if qualified:\n",
    "        charge_num = 1\n",
    "        for c,j in zip(charge_data['charge'],charge_data['cjis']):\n",
    "            if charges == \"\":\n",
    "                charges = \"\\n1) \" + c + \" : \" + j\n",
    "            else:\n",
    "                charges = charges + \" \\n\" + str(charge_num) + \") \" + c + \" : \" + j\n",
    "            charge_num = charge_num + 1\n",
    "\n",
    "        message = row['name'] + \" - \" + row['date'] + charges + \" \\n\" + row['link'] +\" \\n-------------------------\"\n",
    "        slack_data = {'text': message}\n",
    "        headers={'Content-Type': 'application/json'}\n",
    "        url = slack_url\n",
    "        r = requests.post(url, json=slack_data, headers=headers)\n",
    "\n",
    "#Find new cases and post them on slack\n",
    "def compare_cases(new_cases, cookie):\n",
    "    \n",
    "    #load cases from last search\n",
    "    old_cases = pd.read_json('cases.json')\n",
    "    \n",
    "    print(str(len(new_cases)-len(old_cases)) + \" New Cases\")\n",
    "\n",
    "    #see if any results are new and if they are post them on slack\n",
    "    for index, row in new_cases.iterrows():\n",
    "          if row[\"caseId\"] not in old_cases['caseId'].unique():\n",
    "            send_alert(row, cookie)\n",
    "\n",
    "#     new_cases.to_json('cases.json')\n",
    "  \n",
    "#Run bot\n",
    "def runBot():\n",
    "    cookie = getCookie()\n",
    "    cases = getCases(cookie)\n",
    "    compare_cases(cases, cookie)\n",
    "\n",
    "runBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001001', 'items', 'found,', 'displaying', '51', 'to', '1001001.']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "banner = \"1001001 items found, displaying 51 to 1001001.\"\n",
    "splits = banner.split(\" \", 6)\n",
    "print(splits)\n",
    "if (splits[0] == splits[6][:-1]):\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
